{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_disposition</th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>koi_period</th>\n",
       "      <th>koi_period_err1</th>\n",
       "      <th>koi_period_err2</th>\n",
       "      <th>koi_time0bk</th>\n",
       "      <th>koi_time0bk_err1</th>\n",
       "      <th>...</th>\n",
       "      <th>koi_steff_err2</th>\n",
       "      <th>koi_slogg</th>\n",
       "      <th>koi_slogg_err1</th>\n",
       "      <th>koi_slogg_err2</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>koi_srad_err1</th>\n",
       "      <th>koi_srad_err2</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>koi_kepmag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54.418383</td>\n",
       "      <td>2.479000e-04</td>\n",
       "      <td>-2.479000e-04</td>\n",
       "      <td>162.513840</td>\n",
       "      <td>0.003520</td>\n",
       "      <td>...</td>\n",
       "      <td>-81</td>\n",
       "      <td>4.467</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.105</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>291.93423</td>\n",
       "      <td>48.141651</td>\n",
       "      <td>15.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.899140</td>\n",
       "      <td>1.490000e-05</td>\n",
       "      <td>-1.490000e-05</td>\n",
       "      <td>175.850252</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>...</td>\n",
       "      <td>-176</td>\n",
       "      <td>4.544</td>\n",
       "      <td>0.044</td>\n",
       "      <td>-0.176</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.233</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>297.00482</td>\n",
       "      <td>48.134129</td>\n",
       "      <td>15.436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.736952</td>\n",
       "      <td>2.630000e-07</td>\n",
       "      <td>-2.630000e-07</td>\n",
       "      <td>170.307565</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>...</td>\n",
       "      <td>-174</td>\n",
       "      <td>4.564</td>\n",
       "      <td>0.053</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.201</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>285.53461</td>\n",
       "      <td>48.285210</td>\n",
       "      <td>15.597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.525592</td>\n",
       "      <td>3.760000e-06</td>\n",
       "      <td>-3.760000e-06</td>\n",
       "      <td>171.595550</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>...</td>\n",
       "      <td>-211</td>\n",
       "      <td>4.438</td>\n",
       "      <td>0.070</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>1.046</td>\n",
       "      <td>0.334</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>288.75488</td>\n",
       "      <td>48.226200</td>\n",
       "      <td>15.509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.134435</td>\n",
       "      <td>1.050000e-05</td>\n",
       "      <td>-1.050000e-05</td>\n",
       "      <td>172.979370</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>...</td>\n",
       "      <td>-232</td>\n",
       "      <td>4.486</td>\n",
       "      <td>0.054</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.315</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>296.28613</td>\n",
       "      <td>48.224670</td>\n",
       "      <td>15.714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  koi_disposition  koi_fpflag_nt  koi_fpflag_ss  koi_fpflag_co  koi_fpflag_ec  \\\n",
       "0       CONFIRMED              0              0              0              0   \n",
       "1  FALSE POSITIVE              0              1              0              0   \n",
       "2  FALSE POSITIVE              0              1              0              0   \n",
       "3       CONFIRMED              0              0              0              0   \n",
       "4       CONFIRMED              0              0              0              0   \n",
       "\n",
       "   koi_period  koi_period_err1  koi_period_err2  koi_time0bk  \\\n",
       "0   54.418383     2.479000e-04    -2.479000e-04   162.513840   \n",
       "1   19.899140     1.490000e-05    -1.490000e-05   175.850252   \n",
       "2    1.736952     2.630000e-07    -2.630000e-07   170.307565   \n",
       "3    2.525592     3.760000e-06    -3.760000e-06   171.595550   \n",
       "4    4.134435     1.050000e-05    -1.050000e-05   172.979370   \n",
       "\n",
       "   koi_time0bk_err1  ...  koi_steff_err2  koi_slogg  koi_slogg_err1  \\\n",
       "0          0.003520  ...             -81      4.467           0.064   \n",
       "1          0.000581  ...            -176      4.544           0.044   \n",
       "2          0.000115  ...            -174      4.564           0.053   \n",
       "3          0.001130  ...            -211      4.438           0.070   \n",
       "4          0.001900  ...            -232      4.486           0.054   \n",
       "\n",
       "   koi_slogg_err2  koi_srad  koi_srad_err1  koi_srad_err2         ra  \\\n",
       "0          -0.096     0.927          0.105         -0.061  291.93423   \n",
       "1          -0.176     0.868          0.233         -0.078  297.00482   \n",
       "2          -0.168     0.791          0.201         -0.067  285.53461   \n",
       "3          -0.210     1.046          0.334         -0.133  288.75488   \n",
       "4          -0.229     0.972          0.315         -0.105  296.28613   \n",
       "\n",
       "         dec  koi_kepmag  \n",
       "0  48.141651      15.347  \n",
       "1  48.134129      15.436  \n",
       "2  48.285210      15.597  \n",
       "3  48.226200      15.509  \n",
       "4  48.224670      15.714  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"exoplanet_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select your features (columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set features. This will also be used as your x values.\n",
    "selected_features = df.drop(columns=[\"koi_disposition\"])\n",
    "# Drop the null columns where all values are null\n",
    "selected_features = selected_features.dropna(axis='columns', how='all')\n",
    "# Drop the null rows\n",
    "selected_features = selected_features.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Train Test Split\n",
    "\n",
    "Use `koi_disposition` for the y values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = pd.get_dummies(selected_features)\n",
    "y = df[\"koi_disposition\"].values.reshape(-1,1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "Scale the data using the MinMaxScaler and perform some feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\david\\Anaconda3\\envs\\PythonAdv2\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model and add layers\n",
    "model = Sequential()\n",
    "model.add(Dense(units=300, activation='relu', input_dim=X_train_scaled.shape[1]))\n",
    "model.add(Dense(units=300, activation='relu'))\n",
    "model.add(Dense(units=y_train_categorical.shape[1], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5243, 40)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5243, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_categorical.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and fit the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 300)               12300     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 903       \n",
      "=================================================================\n",
      "Total params: 103,503\n",
      "Trainable params: 103,503\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "164/164 - 2s - loss: 0.3885 - accuracy: 0.8404\n",
      "Epoch 2/250\n",
      "164/164 - 0s - loss: 0.2958 - accuracy: 0.8779\n",
      "Epoch 3/250\n",
      "164/164 - 0s - loss: 0.2590 - accuracy: 0.8850\n",
      "Epoch 4/250\n",
      "164/164 - 0s - loss: 0.2549 - accuracy: 0.8919\n",
      "Epoch 5/250\n",
      "164/164 - 0s - loss: 0.2354 - accuracy: 0.8909\n",
      "Epoch 6/250\n",
      "164/164 - 0s - loss: 0.2219 - accuracy: 0.9027\n",
      "Epoch 7/250\n",
      "164/164 - 0s - loss: 0.2149 - accuracy: 0.9062\n",
      "Epoch 8/250\n",
      "164/164 - 0s - loss: 0.2052 - accuracy: 0.9107\n",
      "Epoch 9/250\n",
      "164/164 - 0s - loss: 0.2050 - accuracy: 0.9081\n",
      "Epoch 10/250\n",
      "164/164 - 0s - loss: 0.2102 - accuracy: 0.9084\n",
      "Epoch 11/250\n",
      "164/164 - 0s - loss: 0.1994 - accuracy: 0.9115\n",
      "Epoch 12/250\n",
      "164/164 - 0s - loss: 0.1964 - accuracy: 0.9125\n",
      "Epoch 13/250\n",
      "164/164 - 0s - loss: 0.1897 - accuracy: 0.9180\n",
      "Epoch 14/250\n",
      "164/164 - 0s - loss: 0.1825 - accuracy: 0.9178\n",
      "Epoch 15/250\n",
      "164/164 - 0s - loss: 0.1764 - accuracy: 0.9203\n",
      "Epoch 16/250\n",
      "164/164 - 0s - loss: 0.1669 - accuracy: 0.9256\n",
      "Epoch 17/250\n",
      "164/164 - 0s - loss: 0.1672 - accuracy: 0.9214\n",
      "Epoch 18/250\n",
      "164/164 - 0s - loss: 0.1614 - accuracy: 0.9292\n",
      "Epoch 19/250\n",
      "164/164 - 0s - loss: 0.1606 - accuracy: 0.9298\n",
      "Epoch 20/250\n",
      "164/164 - 0s - loss: 0.1565 - accuracy: 0.9329\n",
      "Epoch 21/250\n",
      "164/164 - 0s - loss: 0.1454 - accuracy: 0.9355\n",
      "Epoch 22/250\n",
      "164/164 - 0s - loss: 0.1409 - accuracy: 0.9411\n",
      "Epoch 23/250\n",
      "164/164 - 0s - loss: 0.1398 - accuracy: 0.9395\n",
      "Epoch 24/250\n",
      "164/164 - 0s - loss: 0.1734 - accuracy: 0.9357\n",
      "Epoch 25/250\n",
      "164/164 - 0s - loss: 0.1876 - accuracy: 0.9357\n",
      "Epoch 26/250\n",
      "164/164 - 0s - loss: 0.1373 - accuracy: 0.9380\n",
      "Epoch 27/250\n",
      "164/164 - 0s - loss: 0.1294 - accuracy: 0.9453\n",
      "Epoch 28/250\n",
      "164/164 - 0s - loss: 0.1181 - accuracy: 0.9495\n",
      "Epoch 29/250\n",
      "164/164 - 0s - loss: 0.1142 - accuracy: 0.9512\n",
      "Epoch 30/250\n",
      "164/164 - 0s - loss: 0.1133 - accuracy: 0.9519\n",
      "Epoch 31/250\n",
      "164/164 - 0s - loss: 0.1118 - accuracy: 0.9537\n",
      "Epoch 32/250\n",
      "164/164 - 0s - loss: 0.1057 - accuracy: 0.9565\n",
      "Epoch 33/250\n",
      "164/164 - 0s - loss: 0.0980 - accuracy: 0.9586\n",
      "Epoch 34/250\n",
      "164/164 - 0s - loss: 0.0990 - accuracy: 0.9573\n",
      "Epoch 35/250\n",
      "164/164 - 0s - loss: 0.0918 - accuracy: 0.9647\n",
      "Epoch 36/250\n",
      "164/164 - 0s - loss: 0.0881 - accuracy: 0.9651\n",
      "Epoch 37/250\n",
      "164/164 - 0s - loss: 0.0931 - accuracy: 0.9613\n",
      "Epoch 38/250\n",
      "164/164 - 0s - loss: 0.0946 - accuracy: 0.9611\n",
      "Epoch 39/250\n",
      "164/164 - 0s - loss: 0.0883 - accuracy: 0.9634\n",
      "Epoch 40/250\n",
      "164/164 - 0s - loss: 0.0737 - accuracy: 0.9710\n",
      "Epoch 41/250\n",
      "164/164 - 0s - loss: 0.0758 - accuracy: 0.9687\n",
      "Epoch 42/250\n",
      "164/164 - 0s - loss: 0.0716 - accuracy: 0.9739\n",
      "Epoch 43/250\n",
      "164/164 - 0s - loss: 0.0843 - accuracy: 0.9670\n",
      "Epoch 44/250\n",
      "164/164 - 0s - loss: 0.0733 - accuracy: 0.9716\n",
      "Epoch 45/250\n",
      "164/164 - 0s - loss: 0.0600 - accuracy: 0.9762\n",
      "Epoch 46/250\n",
      "164/164 - 0s - loss: 0.0578 - accuracy: 0.9800\n",
      "Epoch 47/250\n",
      "164/164 - 0s - loss: 0.0525 - accuracy: 0.9804\n",
      "Epoch 48/250\n",
      "164/164 - 0s - loss: 0.0508 - accuracy: 0.9836\n",
      "Epoch 49/250\n",
      "164/164 - 0s - loss: 0.0488 - accuracy: 0.9823\n",
      "Epoch 50/250\n",
      "164/164 - 0s - loss: 0.1130 - accuracy: 0.9727\n",
      "Epoch 51/250\n",
      "164/164 - 0s - loss: 0.1430 - accuracy: 0.9645\n",
      "Epoch 52/250\n",
      "164/164 - 0s - loss: 0.1169 - accuracy: 0.9704\n",
      "Epoch 53/250\n",
      "164/164 - 0s - loss: 0.0686 - accuracy: 0.9779\n",
      "Epoch 54/250\n",
      "164/164 - 0s - loss: 0.0417 - accuracy: 0.9863\n",
      "Epoch 55/250\n",
      "164/164 - 0s - loss: 0.0362 - accuracy: 0.9889\n",
      "Epoch 56/250\n",
      "164/164 - 0s - loss: 0.0350 - accuracy: 0.9887\n",
      "Epoch 57/250\n",
      "164/164 - 0s - loss: 0.0334 - accuracy: 0.9893\n",
      "Epoch 58/250\n",
      "164/164 - 0s - loss: 0.0318 - accuracy: 0.9918\n",
      "Epoch 59/250\n",
      "164/164 - 0s - loss: 0.0384 - accuracy: 0.9886\n",
      "Epoch 60/250\n",
      "164/164 - 0s - loss: 0.0289 - accuracy: 0.9922\n",
      "Epoch 61/250\n",
      "164/164 - 0s - loss: 0.0315 - accuracy: 0.9897\n",
      "Epoch 62/250\n",
      "164/164 - 0s - loss: 0.0254 - accuracy: 0.9935\n",
      "Epoch 63/250\n",
      "164/164 - 0s - loss: 0.0250 - accuracy: 0.9920\n",
      "Epoch 64/250\n",
      "164/164 - 0s - loss: 0.0239 - accuracy: 0.9937\n",
      "Epoch 65/250\n",
      "164/164 - 0s - loss: 0.0199 - accuracy: 0.9947\n",
      "Epoch 66/250\n",
      "164/164 - 0s - loss: 0.0184 - accuracy: 0.9958\n",
      "Epoch 67/250\n",
      "164/164 - 0s - loss: 0.0226 - accuracy: 0.9924\n",
      "Epoch 68/250\n",
      "164/164 - 0s - loss: 0.0223 - accuracy: 0.9937\n",
      "Epoch 69/250\n",
      "164/164 - 0s - loss: 0.0733 - accuracy: 0.9794\n",
      "Epoch 70/250\n",
      "164/164 - 0s - loss: 0.0830 - accuracy: 0.9720\n",
      "Epoch 71/250\n",
      "164/164 - 0s - loss: 0.0382 - accuracy: 0.9884\n",
      "Epoch 72/250\n",
      "164/164 - 0s - loss: 0.0471 - accuracy: 0.9956\n",
      "Epoch 73/250\n",
      "164/164 - 0s - loss: 0.0225 - accuracy: 0.9962\n",
      "Epoch 74/250\n",
      "164/164 - 0s - loss: 0.0134 - accuracy: 0.9981\n",
      "Epoch 75/250\n",
      "164/164 - 0s - loss: 0.0121 - accuracy: 0.9981\n",
      "Epoch 76/250\n",
      "164/164 - 0s - loss: 0.0137 - accuracy: 0.9979\n",
      "Epoch 77/250\n",
      "164/164 - 0s - loss: 0.0115 - accuracy: 0.9979\n",
      "Epoch 78/250\n",
      "164/164 - 0s - loss: 0.0101 - accuracy: 0.9990\n",
      "Epoch 79/250\n",
      "164/164 - 0s - loss: 0.0082 - accuracy: 0.9989\n",
      "Epoch 80/250\n",
      "164/164 - 0s - loss: 0.0069 - accuracy: 0.9998\n",
      "Epoch 81/250\n",
      "164/164 - 0s - loss: 0.0127 - accuracy: 0.9962\n",
      "Epoch 82/250\n",
      "164/164 - 0s - loss: 0.0564 - accuracy: 0.9771\n",
      "Epoch 83/250\n",
      "164/164 - 0s - loss: 0.0696 - accuracy: 0.9756\n",
      "Epoch 84/250\n",
      "164/164 - 0s - loss: 0.0264 - accuracy: 0.9914\n",
      "Epoch 85/250\n",
      "164/164 - 0s - loss: 0.0128 - accuracy: 0.9981\n",
      "Epoch 86/250\n",
      "164/164 - 0s - loss: 0.0119 - accuracy: 0.9983\n",
      "Epoch 87/250\n",
      "164/164 - 0s - loss: 0.0501 - accuracy: 0.9960\n",
      "Epoch 88/250\n",
      "164/164 - 0s - loss: 0.0407 - accuracy: 0.9947\n",
      "Epoch 89/250\n",
      "164/164 - 0s - loss: 0.0396 - accuracy: 0.9901\n",
      "Epoch 90/250\n",
      "164/164 - 0s - loss: 0.0334 - accuracy: 0.9907\n",
      "Epoch 91/250\n",
      "164/164 - 0s - loss: 0.0075 - accuracy: 0.9998\n",
      "Epoch 92/250\n",
      "164/164 - 0s - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 93/250\n",
      "164/164 - 0s - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 94/250\n",
      "164/164 - 0s - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 95/250\n",
      "164/164 - 0s - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 96/250\n",
      "164/164 - 0s - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 97/250\n",
      "164/164 - 0s - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 98/250\n",
      "164/164 - 0s - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 99/250\n",
      "164/164 - 0s - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 100/250\n",
      "164/164 - 0s - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 101/250\n",
      "164/164 - 0s - loss: 0.0055 - accuracy: 0.9990\n",
      "Epoch 102/250\n",
      "164/164 - 0s - loss: 0.1313 - accuracy: 0.9649\n",
      "Epoch 103/250\n",
      "164/164 - 0s - loss: 0.0669 - accuracy: 0.9767\n",
      "Epoch 104/250\n",
      "164/164 - 0s - loss: 0.0254 - accuracy: 0.9924\n",
      "Epoch 105/250\n",
      "164/164 - 0s - loss: 0.0111 - accuracy: 0.9983\n",
      "Epoch 106/250\n",
      "164/164 - 0s - loss: 0.0406 - accuracy: 0.9964\n",
      "Epoch 107/250\n",
      "164/164 - 0s - loss: 0.0630 - accuracy: 0.9960\n",
      "Epoch 108/250\n",
      "164/164 - 0s - loss: 0.0106 - accuracy: 0.9985\n",
      "Epoch 109/250\n",
      "164/164 - 0s - loss: 0.0041 - accuracy: 0.9998\n",
      "Epoch 110/250\n",
      "164/164 - 0s - loss: 0.0041 - accuracy: 0.9992\n",
      "Epoch 111/250\n",
      "164/164 - 0s - loss: 0.0103 - accuracy: 0.9979\n",
      "Epoch 112/250\n",
      "164/164 - 0s - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 113/250\n",
      "164/164 - 0s - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 114/250\n",
      "164/164 - 0s - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 115/250\n",
      "164/164 - 0s - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 116/250\n",
      "164/164 - 0s - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 117/250\n",
      "164/164 - 0s - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 118/250\n",
      "164/164 - 0s - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 119/250\n",
      "164/164 - 0s - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 120/250\n",
      "164/164 - 0s - loss: 9.5135e-04 - accuracy: 1.0000\n",
      "Epoch 121/250\n",
      "164/164 - 0s - loss: 9.4989e-04 - accuracy: 1.0000\n",
      "Epoch 122/250\n",
      "164/164 - 0s - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 123/250\n",
      "164/164 - 0s - loss: 8.0749e-04 - accuracy: 1.0000\n",
      "Epoch 124/250\n",
      "164/164 - 0s - loss: 7.3232e-04 - accuracy: 1.0000\n",
      "Epoch 125/250\n",
      "164/164 - 0s - loss: 6.3717e-04 - accuracy: 1.0000\n",
      "Epoch 126/250\n",
      "164/164 - 0s - loss: 0.1483 - accuracy: 0.9619\n",
      "Epoch 127/250\n",
      "164/164 - 0s - loss: 0.0549 - accuracy: 0.9809\n",
      "Epoch 128/250\n",
      "164/164 - 0s - loss: 0.0187 - accuracy: 0.9958\n",
      "Epoch 129/250\n",
      "164/164 - 0s - loss: 0.0093 - accuracy: 0.9983\n",
      "Epoch 130/250\n",
      "164/164 - 0s - loss: 0.0071 - accuracy: 0.9989\n",
      "Epoch 131/250\n",
      "164/164 - 0s - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 132/250\n",
      "164/164 - 0s - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 133/250\n",
      "164/164 - 0s - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 134/250\n",
      "164/164 - 0s - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 135/250\n",
      "164/164 - 0s - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 136/250\n",
      "164/164 - 0s - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 137/250\n",
      "164/164 - 0s - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 138/250\n",
      "164/164 - 0s - loss: 9.4616e-04 - accuracy: 1.0000\n",
      "Epoch 139/250\n",
      "164/164 - 0s - loss: 8.5058e-04 - accuracy: 1.0000\n",
      "Epoch 140/250\n",
      "164/164 - 0s - loss: 7.9667e-04 - accuracy: 1.0000\n",
      "Epoch 141/250\n",
      "164/164 - 0s - loss: 7.4586e-04 - accuracy: 1.0000\n",
      "Epoch 142/250\n",
      "164/164 - 0s - loss: 6.3982e-04 - accuracy: 1.0000\n",
      "Epoch 143/250\n",
      "164/164 - 0s - loss: 5.8246e-04 - accuracy: 1.0000\n",
      "Epoch 144/250\n",
      "164/164 - 0s - loss: 5.2507e-04 - accuracy: 1.0000\n",
      "Epoch 145/250\n",
      "164/164 - 0s - loss: 5.2894e-04 - accuracy: 1.0000\n",
      "Epoch 146/250\n",
      "164/164 - 0s - loss: 4.5646e-04 - accuracy: 1.0000\n",
      "Epoch 147/250\n",
      "164/164 - 0s - loss: 4.1168e-04 - accuracy: 1.0000\n",
      "Epoch 148/250\n",
      "164/164 - 0s - loss: 4.0580e-04 - accuracy: 1.0000\n",
      "Epoch 149/250\n",
      "164/164 - 0s - loss: 3.5045e-04 - accuracy: 1.0000\n",
      "Epoch 150/250\n",
      "164/164 - 0s - loss: 3.2910e-04 - accuracy: 1.0000\n",
      "Epoch 151/250\n",
      "164/164 - 0s - loss: 3.0859e-04 - accuracy: 1.0000\n",
      "Epoch 152/250\n",
      "164/164 - 0s - loss: 2.8539e-04 - accuracy: 1.0000\n",
      "Epoch 153/250\n",
      "164/164 - 0s - loss: 2.6276e-04 - accuracy: 1.0000\n",
      "Epoch 154/250\n",
      "164/164 - 0s - loss: 2.3786e-04 - accuracy: 1.0000\n",
      "Epoch 155/250\n",
      "164/164 - 0s - loss: 2.4226e-04 - accuracy: 1.0000\n",
      "Epoch 156/250\n",
      "164/164 - 0s - loss: 2.4659e-04 - accuracy: 1.0000\n",
      "Epoch 157/250\n",
      "164/164 - 0s - loss: 1.9239e-04 - accuracy: 1.0000\n",
      "Epoch 158/250\n",
      "164/164 - 0s - loss: 1.8159e-04 - accuracy: 1.0000\n",
      "Epoch 159/250\n",
      "164/164 - 0s - loss: 1.6084e-04 - accuracy: 1.0000\n",
      "Epoch 160/250\n",
      "164/164 - 0s - loss: 1.6413e-04 - accuracy: 1.0000\n",
      "Epoch 161/250\n",
      "164/164 - 0s - loss: 1.3236e-04 - accuracy: 1.0000\n",
      "Epoch 162/250\n",
      "164/164 - 0s - loss: 1.3922e-04 - accuracy: 1.0000\n",
      "Epoch 163/250\n",
      "164/164 - 0s - loss: 0.0339 - accuracy: 0.9928\n",
      "Epoch 164/250\n",
      "164/164 - 0s - loss: 0.2285 - accuracy: 0.9472\n",
      "Epoch 165/250\n",
      "164/164 - 0s - loss: 0.0838 - accuracy: 0.9821\n",
      "Epoch 166/250\n",
      "164/164 - 0s - loss: 0.0124 - accuracy: 0.9985\n",
      "Epoch 167/250\n",
      "164/164 - 0s - loss: 0.0047 - accuracy: 0.9996\n",
      "Epoch 168/250\n",
      "164/164 - 0s - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 169/250\n",
      "164/164 - 0s - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 170/250\n",
      "164/164 - 0s - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 171/250\n",
      "164/164 - 0s - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 172/250\n",
      "164/164 - 0s - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 173/250\n",
      "164/164 - 0s - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 174/250\n",
      "164/164 - 0s - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 175/250\n",
      "164/164 - 0s - loss: 9.0220e-04 - accuracy: 1.0000\n",
      "Epoch 176/250\n",
      "164/164 - 0s - loss: 8.1946e-04 - accuracy: 1.0000\n",
      "Epoch 177/250\n",
      "164/164 - 0s - loss: 7.4400e-04 - accuracy: 1.0000\n",
      "Epoch 178/250\n",
      "164/164 - 0s - loss: 6.9015e-04 - accuracy: 1.0000\n",
      "Epoch 179/250\n",
      "164/164 - 0s - loss: 6.2678e-04 - accuracy: 1.0000\n",
      "Epoch 180/250\n",
      "164/164 - 0s - loss: 5.7368e-04 - accuracy: 1.0000\n",
      "Epoch 181/250\n",
      "164/164 - 0s - loss: 5.2078e-04 - accuracy: 1.0000\n",
      "Epoch 182/250\n",
      "164/164 - 0s - loss: 4.7956e-04 - accuracy: 1.0000\n",
      "Epoch 183/250\n",
      "164/164 - 0s - loss: 4.4873e-04 - accuracy: 1.0000\n",
      "Epoch 184/250\n",
      "164/164 - 0s - loss: 4.1216e-04 - accuracy: 1.0000\n",
      "Epoch 185/250\n",
      "164/164 - 0s - loss: 3.8505e-04 - accuracy: 1.0000\n",
      "Epoch 186/250\n",
      "164/164 - 0s - loss: 3.5902e-04 - accuracy: 1.0000\n",
      "Epoch 187/250\n",
      "164/164 - 0s - loss: 3.2255e-04 - accuracy: 1.0000\n",
      "Epoch 188/250\n",
      "164/164 - 0s - loss: 2.9793e-04 - accuracy: 1.0000\n",
      "Epoch 189/250\n",
      "164/164 - 0s - loss: 2.7314e-04 - accuracy: 1.0000\n",
      "Epoch 190/250\n",
      "164/164 - 0s - loss: 2.5736e-04 - accuracy: 1.0000\n",
      "Epoch 191/250\n",
      "164/164 - 0s - loss: 2.3274e-04 - accuracy: 1.0000\n",
      "Epoch 192/250\n",
      "164/164 - 0s - loss: 2.2476e-04 - accuracy: 1.0000\n",
      "Epoch 193/250\n",
      "164/164 - 0s - loss: 2.0013e-04 - accuracy: 1.0000\n",
      "Epoch 194/250\n",
      "164/164 - 0s - loss: 1.8540e-04 - accuracy: 1.0000\n",
      "Epoch 195/250\n",
      "164/164 - 0s - loss: 1.7182e-04 - accuracy: 1.0000\n",
      "Epoch 196/250\n",
      "164/164 - 0s - loss: 1.7418e-04 - accuracy: 1.0000\n",
      "Epoch 197/250\n",
      "164/164 - 0s - loss: 1.5047e-04 - accuracy: 1.0000\n",
      "Epoch 198/250\n",
      "164/164 - 0s - loss: 1.3263e-04 - accuracy: 1.0000\n",
      "Epoch 199/250\n",
      "164/164 - 0s - loss: 1.2144e-04 - accuracy: 1.0000\n",
      "Epoch 200/250\n",
      "164/164 - 0s - loss: 1.0987e-04 - accuracy: 1.0000\n",
      "Epoch 201/250\n",
      "164/164 - 0s - loss: 1.0620e-04 - accuracy: 1.0000\n",
      "Epoch 202/250\n",
      "164/164 - 0s - loss: 9.4704e-05 - accuracy: 1.0000\n",
      "Epoch 203/250\n",
      "164/164 - 0s - loss: 9.2444e-05 - accuracy: 1.0000\n",
      "Epoch 204/250\n",
      "164/164 - 0s - loss: 8.6429e-05 - accuracy: 1.0000\n",
      "Epoch 205/250\n",
      "164/164 - 0s - loss: 7.8798e-05 - accuracy: 1.0000\n",
      "Epoch 206/250\n",
      "164/164 - 0s - loss: 0.0870 - accuracy: 0.9847\n",
      "Epoch 207/250\n",
      "164/164 - 0s - loss: 0.1779 - accuracy: 0.9535\n",
      "Epoch 208/250\n",
      "164/164 - 0s - loss: 0.0494 - accuracy: 0.9876\n",
      "Epoch 209/250\n",
      "164/164 - 0s - loss: 0.0094 - accuracy: 0.9985\n",
      "Epoch 210/250\n",
      "164/164 - 0s - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 211/250\n",
      "164/164 - 0s - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 212/250\n",
      "164/164 - 0s - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 213/250\n",
      "164/164 - 0s - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 214/250\n",
      "164/164 - 0s - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 215/250\n",
      "164/164 - 0s - loss: 9.4114e-04 - accuracy: 1.0000\n",
      "Epoch 216/250\n",
      "164/164 - 0s - loss: 8.3032e-04 - accuracy: 1.0000\n",
      "Epoch 217/250\n",
      "164/164 - 0s - loss: 7.4910e-04 - accuracy: 1.0000\n",
      "Epoch 218/250\n",
      "164/164 - 0s - loss: 6.7357e-04 - accuracy: 1.0000\n",
      "Epoch 219/250\n",
      "164/164 - 0s - loss: 6.0769e-04 - accuracy: 1.0000\n",
      "Epoch 220/250\n",
      "164/164 - 0s - loss: 5.5611e-04 - accuracy: 1.0000\n",
      "Epoch 221/250\n",
      "164/164 - 0s - loss: 5.1264e-04 - accuracy: 1.0000\n",
      "Epoch 222/250\n",
      "164/164 - 0s - loss: 4.6752e-04 - accuracy: 1.0000\n",
      "Epoch 223/250\n",
      "164/164 - 0s - loss: 4.2254e-04 - accuracy: 1.0000\n",
      "Epoch 224/250\n",
      "164/164 - 0s - loss: 3.9386e-04 - accuracy: 1.0000\n",
      "Epoch 225/250\n",
      "164/164 - 0s - loss: 3.5950e-04 - accuracy: 1.0000\n",
      "Epoch 226/250\n",
      "164/164 - 0s - loss: 3.2779e-04 - accuracy: 1.0000\n",
      "Epoch 227/250\n",
      "164/164 - 0s - loss: 3.0180e-04 - accuracy: 1.0000\n",
      "Epoch 228/250\n",
      "164/164 - 0s - loss: 2.7933e-04 - accuracy: 1.0000\n",
      "Epoch 229/250\n",
      "164/164 - 0s - loss: 2.5688e-04 - accuracy: 1.0000\n",
      "Epoch 230/250\n",
      "164/164 - 0s - loss: 2.4193e-04 - accuracy: 1.0000\n",
      "Epoch 231/250\n",
      "164/164 - 0s - loss: 2.2172e-04 - accuracy: 1.0000\n",
      "Epoch 232/250\n",
      "164/164 - 0s - loss: 2.0868e-04 - accuracy: 1.0000\n",
      "Epoch 233/250\n",
      "164/164 - 0s - loss: 2.0315e-04 - accuracy: 1.0000\n",
      "Epoch 234/250\n",
      "164/164 - 0s - loss: 1.7443e-04 - accuracy: 1.0000\n",
      "Epoch 235/250\n",
      "164/164 - 0s - loss: 1.6308e-04 - accuracy: 1.0000\n",
      "Epoch 236/250\n",
      "164/164 - 0s - loss: 1.5267e-04 - accuracy: 1.0000\n",
      "Epoch 237/250\n",
      "164/164 - 0s - loss: 1.3481e-04 - accuracy: 1.0000\n",
      "Epoch 238/250\n",
      "164/164 - 0s - loss: 1.2589e-04 - accuracy: 1.0000\n",
      "Epoch 239/250\n",
      "164/164 - 0s - loss: 1.1858e-04 - accuracy: 1.0000\n",
      "Epoch 240/250\n",
      "164/164 - 0s - loss: 1.0584e-04 - accuracy: 1.0000\n",
      "Epoch 241/250\n",
      "164/164 - 0s - loss: 1.0172e-04 - accuracy: 1.0000\n",
      "Epoch 242/250\n",
      "164/164 - 0s - loss: 9.3238e-05 - accuracy: 1.0000\n",
      "Epoch 243/250\n",
      "164/164 - 0s - loss: 8.2604e-05 - accuracy: 1.0000\n",
      "Epoch 244/250\n",
      "164/164 - 0s - loss: 7.8723e-05 - accuracy: 1.0000\n",
      "Epoch 245/250\n",
      "164/164 - 0s - loss: 6.9473e-05 - accuracy: 1.0000\n",
      "Epoch 246/250\n",
      "164/164 - 0s - loss: 6.5059e-05 - accuracy: 1.0000\n",
      "Epoch 247/250\n",
      "164/164 - 0s - loss: 6.1193e-05 - accuracy: 1.0000\n",
      "Epoch 248/250\n",
      "164/164 - 0s - loss: 5.5447e-05 - accuracy: 1.0000\n",
      "Epoch 249/250\n",
      "164/164 - 0s - loss: 5.0524e-05 - accuracy: 1.0000\n",
      "Epoch 250/250\n",
      "164/164 - 0s - loss: 4.6004e-05 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1feac8f58d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=250,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save(\"sequential.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model(\"sequential.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 - 1s - loss: 1.2972 - accuracy: 0.8827\n",
      "Loss: 1.2972373962402344, Accuracy: 0.8827230930328369\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the training data\n",
    "model_loss, model_accuracy = model.evaluate(X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('PythonAdv2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "936b1316dbb2a310ab1a1e05737c1da9bef71d5eedff621d143e0924a05f4e3b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
